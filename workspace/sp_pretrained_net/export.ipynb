{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "\n",
    "class SuperPointNet(torch.nn.Module):\n",
    "  \"\"\" Pytorch definition of SuperPoint Network. \"\"\"\n",
    "  def __init__(self):\n",
    "    super(SuperPointNet, self).__init__()\n",
    "    self.relu = torch.nn.ReLU(inplace=True)\n",
    "    self.pool = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    c1, c2, c3, c4, c5, d1 = 64, 64, 128, 128, 256, 256\n",
    "    # Shared Encoder.\n",
    "    self.conv1a = torch.nn.Conv2d(1, c1, kernel_size=3, stride=1, padding=1)\n",
    "    self.conv1b = torch.nn.Conv2d(c1, c1, kernel_size=3, stride=1, padding=1)\n",
    "    self.conv2a = torch.nn.Conv2d(c1, c2, kernel_size=3, stride=1, padding=1)\n",
    "    self.conv2b = torch.nn.Conv2d(c2, c2, kernel_size=3, stride=1, padding=1)\n",
    "    self.conv3a = torch.nn.Conv2d(c2, c3, kernel_size=3, stride=1, padding=1)\n",
    "    self.conv3b = torch.nn.Conv2d(c3, c3, kernel_size=3, stride=1, padding=1)\n",
    "    self.conv4a = torch.nn.Conv2d(c3, c4, kernel_size=3, stride=1, padding=1)\n",
    "    self.conv4b = torch.nn.Conv2d(c4, c4, kernel_size=3, stride=1, padding=1)\n",
    "    # Detector Head.\n",
    "    self.convPa = torch.nn.Conv2d(c4, c5, kernel_size=3, stride=1, padding=1)\n",
    "    self.convPb = torch.nn.Conv2d(c5, 65, kernel_size=1, stride=1, padding=0)\n",
    "    # Descriptor Head.\n",
    "    self.convDa = torch.nn.Conv2d(c4, c5, kernel_size=3, stride=1, padding=1)\n",
    "    self.convDb = torch.nn.Conv2d(c5, d1, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "  def forward(self, x):\n",
    "    \"\"\" Forward pass that jointly computes unprocessed point and descriptor\n",
    "    tensors.\n",
    "    Input\n",
    "      x: Image pytorch tensor shaped N x 1 x H x W.\n",
    "    Output\n",
    "      semi: Output point pytorch tensor shaped N x 65 x H/8 x W/8.\n",
    "      desc: Output descriptor pytorch tensor shaped N x 256 x H/8 x W/8.\n",
    "    \"\"\"\n",
    "    # Shared Encoder.\n",
    "    x = self.relu(self.conv1a(x))\n",
    "    x = self.relu(self.conv1b(x))\n",
    "    x = self.pool(x)\n",
    "    x = self.relu(self.conv2a(x))\n",
    "    x = self.relu(self.conv2b(x))\n",
    "    x = self.pool(x)\n",
    "    x = self.relu(self.conv3a(x))\n",
    "    x = self.relu(self.conv3b(x))\n",
    "    x = self.pool(x)\n",
    "    x = self.relu(self.conv4a(x))\n",
    "    x = self.relu(self.conv4b(x))\n",
    "    # Detector Head.\n",
    "    cPa = self.relu(self.convPa(x))\n",
    "    semi = self.convPb(cPa)\n",
    "    # Descriptor Head.\n",
    "    cDa = self.relu(self.convDa(x))\n",
    "    desc = self.convDb(cDa)\n",
    "    dn = torch.norm(desc, p=2, dim=1) # Compute the norm.\n",
    "    desc = desc.div(torch.unsqueeze(dn, 1)) # Divide by norm to normalize.\n",
    "    return semi, desc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    def __init__(self):\n",
    "        self.weights_path = './weights/superpoint_v1.pth'\n",
    "        self.cuda = False\n",
    "        self.H = 480\n",
    "        self.W = 640\n",
    "        self.conf_thresh = 0.015 #Detector confidence threshold (default: 0.015).\n",
    "        self.nms_dist = 10 # #Non Maximum Suppression (NMS) distance (default: 4). 非最大值抑制半径\n",
    "\n",
    "cfg = Config()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = SuperPointNet()\n",
    "net.load_state_dict(torch.load(cfg.weights_path,map_location=lambda storage, loc: storage))\n",
    "net.eval()\n",
    "\n",
    "def export_pytorch_jit_model(net,cfg,name):\n",
    "    trace_model = torch.jit.trace(net, torch.Tensor(1, 1, cfg.H, cfg.W))\n",
    "    trace_model.save(f'./weights/{name}_{cfg.W}x{cfg.H}.pt')\n",
    "\n",
    "# export_pytorch_jit_model(net,cfg,'sp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;33mW\u001b[0m \u001b[1;33m__init__: rknn-toolkit2 version: 1.6.0+81f21f4d\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Config model\n",
      "done\n",
      "--> Loading model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading : 100%|████████████████████████████████████████████████████| 26/26 [00:00<00:00, 246.17it/s]\n",
      "\u001b[1;33mW\u001b[0m \u001b[1;33mload_pytorch: The config.mean_values is None, zeros will be set for input 0!\u001b[0m\n",
      "\u001b[1;33mW\u001b[0m \u001b[1;33mload_pytorch: The config.std_values is None, ones will be set for input 0!\u001b[0m\n",
      "\u001b[1;33mW\u001b[0m \u001b[1;33mbuild: The dataset='./dataset.txt' is ignored because do_quantization = False!\u001b[0m\n",
      "I base_optimize ...\n",
      "I base_optimize done.\n",
      "I \n",
      "I fold_constant ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "--> Building model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I fold_constant done.\n",
      "I \n",
      "I correct_ops ...\n",
      "I correct_ops done.\n",
      "I \n",
      "I fuse_ops ...\n",
      "I fuse_ops results:\n",
      "I     convert_unsqueeze_to_reshape: remove node = ['102_Unsqueeze'], add node = ['102_Unsqueeze_2reshape']\n",
      "I     convert_reduce_L2_to_pow_sum_pow: remove node = ['dn.1_ReduceL2'], add node = ['input.1_pow_2', 'input.1_sum', 'input.1_pow_0.5']\n",
      "I     convert_reduce_sum_to_conv: remove node = ['input.1_sum'], add node = ['input.1_sum_2conv', 'input.1_sum_2conv_after']\n",
      "I     unsqueeze_to_4d_pow: remove node = [], add node = ['input.1_pow_0.5_0_unsqueeze0', 'input.1_pow_0.5_0_unsqueeze1']\n",
      "I     fuse_two_reshape: remove node = ['input.1_sum_2conv_after', 'input.1_pow_0.5_0_unsqueeze1']\n",
      "I     fold_constant ...\n",
      "I     fold_constant done.\n",
      "I fuse_ops done.\n",
      "I \n",
      "I sparse_weight ...\n",
      "I sparse_weight done.\n",
      "I \n",
      "\u001b[1;31mE\u001b[0m \u001b[1;31mbuild: Catch exception when building RKNN model!\u001b[0m\n",
      "\u001b[1;31mE\u001b[0m \u001b[1;31mbuild: Traceback (most recent call last):\u001b[0m\n",
      "\u001b[1;31mE\u001b[0m \u001b[1;31mbuild:   File \"rknn/api/rknn_base.py\", line 2034, in rknn.api.rknn_base.RKNNBase.build\u001b[0m\n",
      "\u001b[1;31mE\u001b[0m \u001b[1;31mbuild:   File \"rknn/api/rknn_base.py\", line 399, in rknn.api.rknn_base.RKNNBase._generate_rknn\u001b[0m\n",
      "\u001b[1;31mE\u001b[0m \u001b[1;31mbuild:   File \"rknn/api/rknn_base.py\", line 244, in rknn.api.rknn_base.RKNNBase._build_rknn\u001b[0m\n",
      "\u001b[1;31mE\u001b[0m \u001b[1;31mbuild: ImportError: /lib/x86_64-linux-gnu/libc.so.6: version `GLIBC_2.32' not found (required by /home/codespace/.python/current/lib/python3.10/site-packages/rknn/api/lib/linux-x86_64/cp310/librknnc.so)\u001b[0m\n",
      "\u001b[1;33mW\u001b[0m \u001b[1;33mIf you can't handle this error, please try updating to the latest version of the toolkit2 and runtime from:\n",
      "  https://console.zbox.filez.com/l/I00fc3 (Pwd: rknn)  Path: RKNPU2_SDK / 1.X.X / develop /\n",
      "  If the error still exists in the latest version, please collect the corresponding error logs and the model,\n",
      "  convert script, and input data that can reproduce the problem, and then submit an issue on:\n",
      "  https://redmine.rock-chips.com (Please consult our sales or FAE for the redmine account)\u001b[0m\n",
      "\u001b[1;31mE\u001b[0m \u001b[1;31mexport_rknn: RKNN model is None, please load & build model first!\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model failed!\n",
      "done\n",
      "--> Export rknn model\n",
      "Export rknn model failed!\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "from rknn.api import RKNN\n",
    "# Create RKNN object\n",
    "rknn = RKNN(verbose=True)\n",
    "\n",
    "input_size_list = [[1, 1, cfg.H, cfg.W]]\n",
    "\n",
    "# Pre-process config\n",
    "print('--> Config model')\n",
    "rknn.config( target_platform='rk3588')\n",
    "print('done')\n",
    "\n",
    "# Load model\n",
    "print('--> Loading model')\n",
    "ret = rknn.load_pytorch(model=f'./weights/sp_{cfg.W}x{cfg.H}.pt', input_size_list=input_size_list)\n",
    "if ret != 0:\n",
    "    print('Load model failed!')\n",
    "    exit(ret)\n",
    "print('done')\n",
    "\n",
    "# Build model\n",
    "print('--> Building model')\n",
    "ret = rknn.build(do_quantization=False, dataset='./dataset.txt')\n",
    "if ret != 0:\n",
    "    print('Build model failed!')\n",
    "    exit(ret)\n",
    "print('done')\n",
    "\n",
    "# Export rknn model\n",
    "print('--> Export rknn model')\n",
    "ret = rknn.export_rknn(f'./sp_{cfg.W}x{cfg.H}.rknn')\n",
    "if ret != 0:\n",
    "    print('Export rknn model failed!')\n",
    "    exit(ret)\n",
    "print('done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
